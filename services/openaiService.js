require('dotenv').config();
process.env.NODE_TLS_REJECT_UNAUTHORIZED = '0';
const dayjs = require('dayjs');
const { loadAgent } = require('../app/engine/loader');
const { OpenAI } = require('openai');
const openai = new OpenAI({ apiKey: process.env.OPENAI_API_KEY });
const { INTENTS, getIntentByCodigo } = require('../app/models/IntentModel');

function logPrompt(title, body = '') {
  console.log(
    `\n====== ${title.toUpperCase()} ======\n` +
    (typeof body === 'string'
      ? body.replace(/\\n/g, '\n').replace(/\\"/g, '"')
      : JSON.stringify(body, null, 2)
    ) +
    '\n===============================\n'
  );
}


function gerarTodasAsIntentsPrompt() {
  return INTENTS.map(i => {
    const p = i.gerarPrompt();
    return `// ${i.nome}
      intent: "${p.intent}"
      descri√ß√£o: ${p.descricao}`;
  }).join('\n\n');
}


async function gerarMensagemDaIntent({
  intent,
  agentId = 'default-agent',
  dados = {},
  promptExtra = ''
}) {
  const agent = loadAgent(agentId);
  const intentData = INTENTS.find(i => i.codigo === intent);

  const sugestoesDeRespostas = intentData?.responses?.length
    ? `Alguns exemplos de como voc√™ pode responder:\n${intentData.responses.map(r => `- ${r}`).join('\n')}`
    : '';

  const prompt = `
Voc√™ √© ${agent.nome}, sua fun√ß√£o √© ${agent.role}. Voc√™ tem a seguinte personalidade: ${agent.personality}

${intent === 'aleatorio' 
  ? 'Fa√ßa um small talk com a mensagem recebida (veja em "Contexto extra") e retome o assunto anterior.' 
  : `Sua miss√£o √© ajudar o usu√°rio com base na inten√ß√£o atual: "${intent}".`}

Contexto principal: ${JSON.stringify(dados)}
Contexto extra: ${promptExtra}

${sugestoesDeRespostas}

Retorne SOMENTE a mensagem final para o usu√°rio (sem JSON).
`;

  logPrompt('prompt Mensagem:', prompt);

  try {
    const resposta = await openai.chat.completions.create({
      model: 'gpt-4o-mini',
      messages: [
        { role: 'system', content: agent.personality },
        { role: 'user', content: prompt }
      ],
      temperature: 0.3
    });

    return resposta.choices[0].message.content.trim();
  } catch (error) {
    logPrompt('‚ùå Erro ao gerar resposta da intent:', error);
    return 'Desculpa, n√£o consegui processar isso agora. Pode repetir?';
  }
}

/**
 * Detecta a nova inten√ß√£o do usu√°rio com base na conversa anterior.
 */
async function detectarIntentComContexto({
  mensagem,
  agentId = 'default-agent',
  promptExtra = '',
  intentAnterior = '',
  mensagemAnterior = '',
  tipoUltimaPergunta = ''  
}) {
  const agent = loadAgent(agentId);
  const blocoDeIntents = gerarTodasAsIntentsPrompt();

  const prompt = `
Voc√™ √© ${agent.nome}, um assistente da Ibiunet.
Sua fun√ß√£o √© analisar a mensagem do cliente e detectar qual a inten√ß√£o dele, com base nas op√ß√µes dispon√≠veis abaixo.

### Regras Fixas:
1. Se identificar 11 n√∫meros seguidos ‚Üí **extrair_cpf**.
2. Se mencionar "CPF" mas sem n√∫mero ‚Üí **aleatorio**.
3. Se disser "primeira", "segunda", "terceira" ‚Üí **escolher_os**.
4. Se disser "ok", "pode ser", "fechado" ou similares:
   - Se a √öLTIMA PERGUNTA foi sobre **agendamento**, e a resposta √© de aceita√ß√£o ‚Üí **confirmar_agendamento**.
   - Se foi sobre **escolha de OS**, e a resposta √© de aceita√ß√£o ‚Üí **confirmar_escolha_os**.
5. Se o usu√°rio pedir para **sugerir hor√°rio**, **escolher outro hor√°rio**, ou **pedir uma nova op√ß√£o de data/hora** ‚Üí **agendar_data**.


### Contexto da conversa:
- √öltima intent detectada: ${intentAnterior || '‚Äî'}
- √öltima pergunta feita ao cliente: "${mensagemAnterior || '‚Äî'}"
- Tipo da √∫ltima pergunta: "${tipoUltimaPergunta || '‚Äî'}"
- Nova mensagem do cliente: "${mensagem}"

Resumo adicional:
${promptExtra.replace(/\\n/g, '\n')}

### Intents dispon√≠veis:
${blocoDeIntents}

Retorne APENAS o JSON:
{ "intent": "nome_da_intent" }
`;

  logPrompt('prompt Intent', prompt);

  try {
    const resposta = await openai.chat.completions.create({
      model: 'gpt-4o-mini',
      messages: [
        { role: 'system', content: agent.personality },
        { role: 'user', content: prompt }
      ],
      temperature: 0.2
    });

    return JSON.parse(resposta.choices[0].message.content);
  } catch (error) {
    logPrompt('‚ùå Erro ao detectar intent:', error);
    return { intent: 'aleatorio' };
  }
}


/**
 * Gera uma resposta com base nos filhos da intent atual.
 */
async function gerarMensagemDaIntent({
  intent,
  agentId = 'default-agent',
  dados = {},
  promptExtra = ''
}) {
  const agent = loadAgent(agentId);

  const prompt = `
Voc√™ √© ${agent.nome}, sua fun√ß√£o √© ${agent.role} sua personalidade √©  ${agent.personality} 

${intent === 'aleatorio' ? 'Fa√ßa um small talk com a mensagem recebida (nova mensagem enviada dentro de Contexto Extra) do usu√°rio e retome o assunto' : 'Sua miss√£o √© ajudar o usu√°rio com base na inten√ß√£o atual:'+ intent}

${intent !== 'inicio' ? '*N√ÉO* repita sauda√ß√µes (Ol√°/Oi/Boa ‚Ä¶) se j√° houver saudado nas mensagens anteriores.' : 'Sua miss√£o √© ajudar o usu√°rio com base na inten√ß√£o atual:'+ intent}

Contexto PRINCIPAL: ${JSON.stringify(dados)}
Contexto extra: ${promptExtra}

Retorne SOMENTE a mensagem final para o usu√°rio (sem JSON).
`;



// Baseie-se APENAS nas seguintes possibilidades de resposta (intents filhas do fluxo atual):

// ${filhosPrompt}

logPrompt('prompt Mensagem:', prompt);
  try {
    const resposta = await openai.chat.completions.create({
      model: 'gpt-4o-mini',
      messages: [
        { role: 'system', content: agent.personality },
        { role: 'user', content: prompt }
      ],
      temperature: 0.3
    });

    return resposta.choices[0].message.content.trim();
  } catch (error) {
    logPrompt('‚ùå Erro ao gerar resposta da intent:', error);
    return 'Desculpa, n√£o consegui processar isso agora. Pode repetir?';
  }
}

async function interpretarMensagem({
  mensagem,
  agentId = 'default-agent',
  promptExtra = '',
  intentAnterior = '',
  mensagemAnterior = ''
}) {
  if (!mensagem || typeof mensagem !== 'string') {
    logPrompt('‚ùå Mensagem inv√°lida recebida para interpreta√ß√£o:', mensagem);
    return {
      intent: 'default',
      data: {},
      mensagem: 'Desculpa, n√£o consegui entender o que voc√™ quis dizer. Pode tentar de novo?'
    };
  }

  const agent = loadAgent(agentId);

  /**
   * Observa√ß√£o:
   * - No "promptExtra", esperamos vir dados como:
   *   "O usu√°rio se chama Fulano e gosta de alien√≠genas e futebol.
   *    Por favor, fa√ßa small talk sobre isso antes de retomar o assunto principal."
   * - Assim, o GPT ter√° esse contexto e poder√° usar esses detalhes na resposta.
   */
  const prompt = `
Voc√™ √© ${agent.nome}, um assistente focado em atender clientes de forma amig√°vel e eficiente. Sua fun√ß√£o: ${agent.role}.

Use este contexto adicional para estabelecer uma pequena conversa (small talk) sobre o que estiver descrito (nome, interesses etc.), mas sem fugir do seu objetivo principal de suporte.

Caso isso aconte√ßa diga que est√° em horario de trabalho e n√£o pode falar sobre isso, mas quem sabe depois?

Evite responder as frases com uma sauda√ß√£o do tipo Ol√°! S√≥ fale caso tenha certeza que √© a primeira intera√ß√£o do dia e a intent igual a "inicio"

Depois de fazer uma r√°pida men√ß√£o a esse contexto (se existir), interprete a mensagem do usu√°rio e retorne **APENAS** o JSON no seguinte formato:

{
  "intent": "nome_da_intent",
  "data": {},
  "mensagem": "resposta amig√°vel ao usu√°rio, incluindo um pouco do small talk"
}

Contexto anterior:
- √öltima inten√ß√£o: "${intentAnterior}"
- Pergunta anterior: "${mensagemAnterior}"
- Nova mensagem do usu√°rio: "${mensagem}"

*IMPORTANTE*
Se a "Pergunta anterior" tiver alguma sauda√ß√£o do tipo (Oi, Ol√° etc) e a intent anterior for diferente de inicial, n√£o de nenhuma sauda√ß√£o.

### Dados adicionais (promptExtra) Utilize apenas o √∫ltimo inserido caso preciso, evite usar essas informa√ß√µes, s√≥ utilize se for perguntado.
Os topicos abaixo est√£o separados por quebra de linha, se a proxima resposta (Nova mensagem do usu√°rio) n√£o tiver rela√ß√£o/continuidade com a mensagem a (Pergunta anterior) voc√™ volta a pedir o CPF para iniciar o atendimento de agendamento.
${promptExtra}

### Intents poss√≠veis


1) "inicio"  
   - Quando o usu√°rio inicia ou sa√∫da.
   - Exemplo de resposta (apenas uma vez): 
     {
       "intent": "inicio",
       "data": {},
       "mensagem": "Ol√°, sou ${agent.nome} da Ibiunet! Tudo bem? Poderia me enviar seu CPF para iniciarmos o atendimento?"
     }

2) "aleatorio"  
   - Se o usu√°rio fala algo fora do fluxo ou fora do contexto (ex.: aliens, futebol, etc.).
   - Responda curto e tente puxar o assunto de volta para CPF, agendamento, OS etc.
   - Exemplo:
     {
       "intent": "aleatorio",
       "data": {},
       "mensagem": "Legal (Mostrar interesse sobre o que foi dito), mas primeiro eu vou precisar te identificar! Me mande seu CPF para a gente iniciar."
     }

3) "extrair_cpf"  
   - O usu√°rio est√° informando o CPF. Ex:(522.473.726-51 ; 52247372651) deve conter 11 digitos menos que nova a intent deve ser considerada escolher_os
   - Exemplo:
     {
       "intent": "extrair_cpf",
       "data": {},
       "mensagem": "Ok, CPF recebido! J√° vou verificar seus dados."
     }

4) "verificar_os"  
   - Ex.: "Quero consultar minha OS" ou "Que dia o t√©cnico vem?" 
   - Exemplo:
     {
       "intent": "verificar_os",
       "data": {},
       "mensagem": "Certo, vou dar uma olhada nas suas OS. S√≥ um instante."
     }

5) "escolher_os"  
   - O usu√°rio escolhe ou informa qual OS quer editar/agendar. Pode vir apenas como um n√∫mero sempre menor que 9 digitos. verificar 
   - Exemplo:
     {
       "intent": "escolher_os",
       "data": {},
       "mensagem": "Entendi, voc√™ escolheu a OS 1234. Agora podemos agendar ou atualizar."
     }

6) "agendar_data"  
   - O usu√°rio pede explicitamente para agendar ou marcar visita.
   - Exemplo:
     {
       "intent": "agendar_data",
       "data": {},
       "mensagem": "Claro! Qual dia seria melhor para voc√™?"
     }

7) "extrair_data"  
   - O usu√°rio mencionou datas em linguagem natural (ex.: amanh√£, s√°bado, dia 20).
   - Exemplo:
     {
       "intent": "extrair_data",
       "data": {},
       "mensagem": "Voc√™ mencionou essa data. Vou interpret√°-la e confirmar."
     }

8) "confirmar_agendamento"  
   - O usu√°rio confirma a data final que deseja.
   - Exemplo:
     {
       "intent": "confirmar_agendamento",
       "data": {},
       "mensagem": "Perfeito, confirmando sua visita. Qualquer mudan√ßa, me avise."
     }

9) "finalizado"
   - Fluxo conclu√≠do ou usu√°rio se despediu.
   - Exemplo:
     {
       "intent": "finalizado",
       "data": {},
       "mensagem": "√ìtimo, encerramos por aqui. Obrigado pelo contato e at√© mais!"
     }

12) "extrair_hora"  
   - O usu√°rio mencionou datas em linguagem natural (ex.: amanh√£, s√°bado, dia 20) e tamb√©m horario ( 10 da manh√£, final da tarde etc)
   - Exemplo:
     {
       "intent": "extrair_hora",
       "data": {},
       "mensagem": "Voc√™ mencionou essa data. Vou interpret√°-la e confirmar."
     }

Importante: **retorne APENAS o JSON** (sem texto fora do objeto JSON). Se n√£o tiver certeza, use "aleatorio" ou "desconhecido".
`;

  logPrompt('Interpretar intencao promptExtra:', prompt);

  try {
    const resposta = await openai.chat.completions.create({
      model: 'gpt-3.5-turbo',
      messages: [
        { role: 'system', content: agent.personality },
        { role: 'user', content: prompt }
      ],
      temperature: 0.2
    });

    const respostaText = resposta.choices[0].message.content;
    return JSON.parse(respostaText);

  } catch (error) {
    logPrompt('‚ùå Erro no OpenAI:', error);
    return {
      intent: 'default',
      data: {},
      mensagem: 'Desculpa, n√£o entendi o que voc√™ quis dizer. Pode tentar de novo?'
    };
  }
}

/**
 * Gera uma resposta ao usu√°rio com base numa intent conhecida.
 * Pode receber um texto extra (promptAuxiliar) para dar contexto adicional.
 *
 * @param {string} intent
 * @param {string} [agentId='default-agent']
 * @param {Object} [dados={}]
 * @param {string} [promptAuxiliar='']
 * @returns {Promise<string>}
 */
async function responderComBaseNaIntent(intent, agentId = 'default-agent', dados = {}, promptAuxiliar = '') {
  const agent = loadAgent(agentId) || { nome: 'Assistente', role: 'ajudar o usu√°rio de forma gentil e eficaz.' };

  //logPrompt('üîç Agent carregado:', agent);

  const prompt = `
Voc√™ √© ${agent.nome}, um assistente que deve ajudar o usu√°rio com base na inten√ß√£o: "${intent}".
Sua fun√ß√£o: ${agent.role}.
Use tom informal e amig√°vel, como conversando com o cliente.

Dados adicionais: ${JSON.stringify(dados)}
Contexto extra: ${promptAuxiliar}

Exemplos de resposta:
- "inicio": "Ol√°! Como posso te ajudar? Se quiser, mande seu CPF."
- "aleatorio": Essa intent pode variar muito mas tente fazer com que o usuario responta a pergunta anterior que era " ${JSON.stringify(dados.mensagemAnteriorCliente)}
- "help": "Posso te ajudar a informar seu CPF ou a marcar seu agendamento, √© s√≥ pedir."
- "os_nao_encontrada": 

Retorne SOMENTE a frase (sem JSON).
`;

 logPrompt('### PROMPT INTEN√á√ÉO ###:', prompt);

  try {
    const resposta = await openai.chat.completions.create({
      model: 'gpt-3.5-turbo',
      messages: [
        { role: 'system', content: agent.personality },
        { role: 'user', content: prompt }
      ],
      temperature: 0.5
    });

    return resposta.choices[0].message.content.trim();

  } catch (error) {
    logPrompt('‚ùå Erro ao gerar resposta por intent:', error);
    return 'Desculpa, tive um problema aqui. Tenta de novo rapidinho?';
  }
}

/**
 * Tenta interpretar uma data na mensagem do usu√°rio (linguagem natural).
 * Retorna "YYYY-MM-DD" ou null caso n√£o consiga identificar.
 *
 * @param {string} mensagem
 * @returns {Promise<string|null>}
 */
async function interpretarDataNatural(mensagem) {
  const prompt = `
Voc√™ √© um assistente que interpreta datas em linguagem natural e retorna sempre no seguinte formato JSON:
Voc√™ deve encontrar o valor da variavel "sugestao_datas" onde respeitando o valor maximo de SLA de (XXX)

{
  "data_interpretada": "YYYY-MM-DD",
  "sugestao_datas": "String"
}

Tente identificar a data mencionada pelo usu√°rio com base na data atual. Caso n√£o encontre nenhuma data v√°lida, responda:

{
  "data_interpretada": null,
  "sugestao_datas": "String"
}

Frase do usu√°rio: "${mensagem}"
Hoje √©: ${dayjs().format('YYYY-MM-DD')}

Retorne APENAS o JSON, sem mais nada.
`;

  try {
    const resposta = await openai.chat.completions.create({
      model: 'gpt-3.5-turbo',
      messages: [
        { role: 'system', content: 'Voc√™ √© um assistente que interpreta datas informais.' },
        { role: 'user', content: prompt }
      ],
      temperature: 0.1
    });

    const json = JSON.parse(resposta.choices[0].message.content);
    logPrompt('data interpretada:', json.data_interpretada);
    return json.data_interpretada;
  } catch (error) {
    logPrompt('‚ùå Erro ao interpretar data:', error);
    return null;
  }
}

async function interpretaDataePeriodo({ mensagem, agentId = 'default-agent', dados = {}, promptExtra = '' }) {
  const agent = require('../app/engine/loader').loadAgent(agentId);
  const prompt = `
Voc√™ √© ${agent.nome}, sua fun√ß√£o √© ${agent.role}. Voc√™ tem a seguinte personalidade: ${agent.personality}

Seu objetivo √© identificar tanto a data quanto o per√≠odo do dia (manh√£ ou tarde) mencionados pelo usu√°rio. O per√≠odo deve ser "M" para manh√£ ou "T" para tarde.

Contexto principal: ${JSON.stringify(dados)}
Contexto extra: ${promptExtra}

Responda neste formato JSON:
{
  "data_interpretada": "YYYY-MM-DD",
  "periodo_interpretado": "M" // manh√£
  // ou "T" para tarde
}

Se n√£o entender a data ou per√≠odo, preencha com null.

Frase do usu√°rio: "${mensagem}"
Hoje √©: ${dayjs().format('YYYY-MM-DD')}
`;

  try {
    const resposta = await openai.chat.completions.create({
      model: 'gpt-3.5-turbo',
      messages: [{ role: 'user', content: prompt }],
      temperature: 0.1
    });

    const json = JSON.parse(resposta.choices[0].message.content);
    return json;
  } catch (error) {
    console.error('Erro ao interpretar data e hora:', error);
    return {
      data_interpretada: null,
      periodo_interpretado: null
    };
  }
}


async function interpretaHora(mensagem) {
  const prompt = `
Voc√™ √© um assistente que interpreta hor√°rios em linguagem natural e retorna sempre no seguinte formato JSON:

{
  "hora_interpretada": "HH:mm:00"
}

Tente identificar o hor√°rio mencionado pelo usu√°rio com base na frase. Caso n√£o encontre nenhuma hora v√°lida, responda:

{
  "hora_interpretada": null
}

Frase do usu√°rio: "${mensagem}"

Retorne APENAS o JSON, sem mais nada.
`;

  try {
    const resposta = await openai.chat.completions.create({
      model: 'gpt-3.5-turbo',
      messages: [
        { role: 'system', content: 'Voc√™ √© um assistente que interpreta hor√°rios informais.' },
        { role: 'user', content: prompt }
      ],
      temperature: 0.1
    });

    const json = JSON.parse(resposta.choices[0].message.content);
    logPrompt('hora interpretada:', json.hora_interpretada);
    return json.hora_interpretada;
  } catch (error) {
    logPrompt('‚ùå Erro ao interpretar hora:', error);
    return null;
  }
}


async function interpretarNumeroOS({ mensagem, osList = [], agentId = '', dados = {}, promptExtra = '' }) {
  /* --------  monta lista reduzida  -------- */
  const listaReduzida = osList
    .map((o, i) => `${i + 1}) ${o.id} - ${o.titulo || o.mensagem || 'Sem descri√ß√£o'}`)
    .join('\n');

  let contextoExtra = '';
  if (dados && Object.keys(dados).length > 0) {
    contextoExtra += `\nDados adicionais: ${JSON.stringify(dados)}`;
  }
  if (promptExtra) {
    contextoExtra += `\nContexto extra: ${promptExtra}`;
  }

  const prompt = `
Voc√™ √© um assistente que identifica qual Ordem de Servi√ßo (OS) o usu√°rio quer.

### Lista de OS abertas
${listaReduzida}

### Contexto
${contextoExtra}

### Como o usu√°rio pode se referir a uma OS
- Pelo **n√∫mero** da OS (ex.: "12310")
- Pela **posi√ß√£o na lista** (ex.: "Quero a primeira", "pego a 2¬™", "a terceira")

### Regras de interpreta√ß√£o
1. Se o usu√°rio usar posi√ß√£o ("primeira", "1", "1¬™"), mapeie para o ID que est√° nessa posi√ß√£o na lista.
2. Se digitar um n√∫mero que **n√£o est√°** na lista, retorne null.
3. Ignore palavras irrelevantes (ex.: ‚Äúquero‚Äù, ‚Äúa‚Äù, ‚Äúpegar‚Äù).
4. Somente n√∫meros de at√© 9 d√≠gitos s√£o considerados ID de OS.

### Formato de resposta (APENAS JSON)
Exemplo sucesso:  { "os": "12310" }
Exemplo falha:    { "os": null }

Frase do usu√°rio: "${mensagem}"
`;

  logPrompt('prompt encontra os', prompt);

  try {
    const resposta = await openai.chat.completions.create({
      model: 'gpt-3.5-turbo',
      messages: [
        { role: 'system', content: `Voc√™ √© um assistente que interpreta sele√ß√£o de OS.${agentId ? ' Agente: ' + agentId : ''}` },
        { role: 'user',   content: prompt }
      ],
      temperature: 0.1
    });

    const json = JSON.parse(resposta.choices[0].message.content || '{}');
    logPrompt('os interpretada:', json.os);

    /* -------------- devolve o ID (ou null) -------------- */
    return json.os ?? null;

  } catch (error) {
    logPrompt('‚ùå Erro ao interpretar OS:', error);
    return null;
  }
}
async function interpretarEscolhaOS({ mensagem, osList = [], agentId = '', dados = {}, promptExtra = '' }) {
  const lista = osList.map((o, i) => `${i + 1}) ${o.id} - ${o.titulo || o.mensagem || 'Sem descri√ß√£o'}`).join('\n');

  let contextoExtra = '';
  if (dados && Object.keys(dados).length > 0) {
    contextoExtra += `\nContexto do usu√°rio: ${JSON.stringify(dados)}`;
  }
  if (promptExtra) {
    contextoExtra += `\nObserva√ß√£o: ${promptExtra}`;
  }

  const prompt = `
Voc√™ √© um assistente que ajuda o cliente a escolher uma Ordem de Servi√ßo (OS).

### Lista de OS dispon√≠veis:
${lista}
${contextoExtra}

### Instru√ß√µes:
- O cliente pode falar de maneira livre: ("quero a primeira", "prefiro o segundo", "vou querer a 3¬™", "primeiro serve", etc).
- Seu trabalho √© interpretar qual posi√ß√£o ele quis (1, 2, 3...).
- Se identificar claramente, responda o √≠ndice em JSON:
  { "posicao": 1 }
- Se n√£o identificar, retorne:
  { "posicao": null }

Frase do cliente:
"${mensagem}"

Responda APENAS o JSON pedido.
`;

  const resposta = await openai.chat.completions.create({
    model: 'gpt-4o-mini',
    messages: [
      { role: 'system', content: `Voc√™ √© um assistente de atendimento.${agentId ? ' Agente: ' + agentId : ''}` },
      { role: 'user', content: prompt }
    ],
    temperature: 0.1
  });

  const json = JSON.parse(resposta.choices[0].message.content);
  return json.posicao ?? null;
}



module.exports = {
  interpretarMensagem,
  responderComBaseNaIntent,
  interpretarDataNatural,
  interpretaHora,
  detectarIntentComContexto,
  gerarMensagemDaIntent,
  interpretarNumeroOS,
  interpretarEscolhaOS
  
};
